{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# https://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-python\n",
    "# Simple reinforcement learning algorithm for learning tic-tac-toe\n",
    "# Use the update rule: V(s) = V(s) + alpha*(V(s') - V(s))\n",
    "# Use the epsilon-greedy policy:\n",
    "#   action|s = argmax[over all actions possible from state s]{ V(s) }  if rand > epsilon\n",
    "#   action|s = select random action from possible actions from state s if rand < epsilon\n",
    "#\n",
    "#\n",
    "# INTERESTING THINGS TO TRY:\n",
    "#\n",
    "# Currently, both agents use the same learning strategy while they play against each other.\n",
    "# What if they have different learning rates?\n",
    "# What if they have different epsilons? (probability of exploring)\n",
    "#   Who will converge faster?\n",
    "# What if one agent doesn't learn at all?\n",
    "#   Poses an interesting philosophical question: If there's no one around to challenge you,\n",
    "#   can you reach your maximum potential?\n",
    "# What happends if you change learning rate i.e. alpha.\n",
    "# Does the epsilon value change makes agent more intelligent\n",
    "#   How about decaying epsilon\n",
    "# How many times should two AI agents play against each other.\n",
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "\n",
    "# size of tic tac toe game\n",
    "LENGTH = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class represents a tic tac toe game\n",
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((LENGTH, LENGTH))\n",
    "        self.x = 1   # represents an x on the board for player 1\n",
    "        self.o = -1  # represents an o on the board for player 2\n",
    "        self.ended = False\n",
    "        self.winner = None\n",
    "        self.num_states = 3**(LENGTH*LENGTH)\n",
    "        \n",
    "        \n",
    "    def game_over(self):\n",
    "        # returns true is game is over i.e. if a player won or it's a draw\n",
    "        # otherwise returns false\n",
    "        for player in [self.x, self.o]:\n",
    "            # check all rows for winner\n",
    "            for i in range(LENGTH):\n",
    "                if self.board[i].sum() == player*LENGTH:\n",
    "                    self.winner = player\n",
    "                    self.ended = True\n",
    "                    return True\n",
    "            \n",
    "            # check all columns for winner\n",
    "            for j in range(LENGTH):\n",
    "                if self.board[:,j].sum() == player*LENGTH:\n",
    "                    self.winner = player\n",
    "                    self.ended = True\n",
    "                    return True\n",
    "            \n",
    "            # check all diagonals for winner\n",
    "            # check left to right diagonal\n",
    "            if np.trace(self.board) == player*LENGTH:\n",
    "                self.winner = player\n",
    "                self.ended = True\n",
    "                return True\n",
    "            \n",
    "            # check right to left diagonal\n",
    "            elif np.trace(np.flip(self.board, axis=0)) == player*LENGTH:\n",
    "                self.winner = player\n",
    "                self.ended = True\n",
    "                return True\n",
    "            \n",
    "        # check if it is a draw\n",
    "        if np.all((self.board==0)==False):\n",
    "            self.winner = None\n",
    "            self.ended = True\n",
    "            return True\n",
    "        \n",
    "        # game is not over\n",
    "        self.winner = None\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def is_empty(self, i, j):\n",
    "        return self.board[i,j]==0\n",
    "    \n",
    "    \n",
    "    def reward(self, sym):\n",
    "        # no reward until game is over\n",
    "        if not self.game_over():\n",
    "            return 0\n",
    "        \n",
    "        # if game is over\n",
    "        # sym will be self.x or self.o\n",
    "        return 1 if self.winner==sym else 0\n",
    "           \n",
    "        \n",
    "    def get_state(self):\n",
    "        # returns the current state as an int\n",
    "        # this is like finding the integer respresented by a base-3 number\n",
    "        # consider the example of converting a binary number to decimal\n",
    "        k=0\n",
    "        state=0\n",
    "        for i in range(LENGTH):\n",
    "            for j in range(LENGTH):\n",
    "                if self.board[i,j]==0:\n",
    "                    v=0\n",
    "                elif self.board[i,j]==self.x:\n",
    "                    v=1\n",
    "                elif self.board[i,j]==self.o:\n",
    "                    v=2\n",
    "                state += (3**k)*v\n",
    "                k += 1\n",
    "        return state\n",
    "    \n",
    "    # Example board\n",
    "    # -------------\n",
    "    # | x |   |   |\n",
    "    # -------------\n",
    "    # |   |   |   |\n",
    "    # -------------\n",
    "    # |   |   | o |\n",
    "    # -------------\n",
    "\n",
    "    \n",
    "    def draw_board(self):\n",
    "        for i in range(LENGTH):\n",
    "            print('-------------')\n",
    "            for j in range(LENGTH):\n",
    "                if self.board[i,j] == self.x:\n",
    "                    print(\"| x \", end=\"\")\n",
    "                elif self.board[i,j] == self.o:\n",
    "                    print(\"| o \", end=\"\")\n",
    "                else:\n",
    "                    print(\"|   \", end=\"\")\n",
    "            print(\"|\")\n",
    "        print('-------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, eps=0.1, alpha=0.5, verbose=False):\n",
    "        self.eps = eps  # probability of choosing a random action instead of greedy\n",
    "        self.verbose = verbose\n",
    "        self.state_history = []\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        \n",
    "    def set_symbol(self, sym):\n",
    "        self.sym = sym\n",
    "        \n",
    "        \n",
    "    def set_V(self, V):\n",
    "        self.V = V\n",
    "        \n",
    "        \n",
    "    def reset_history(self):\n",
    "        self.state_history = []\n",
    "        \n",
    "        \n",
    "    def update_state_history(self, s):\n",
    "        # cannot put this in take_action, because take_action only happens\n",
    "        # once every other iteration for each player while state history needs\n",
    "        # to be udpdated every iteration for both players\n",
    "        self.state_history.append(s)\n",
    "        \n",
    "        \n",
    "    def take_action(self, env):\n",
    "        # choose an action based on epsilon-greedy strategy\n",
    "        r = np.random.rand()\n",
    "        if r < self.eps:\n",
    "            # take a random action\n",
    "            if self.verbose:\n",
    "                print('Taking a random action')\n",
    "            \n",
    "            # check for empty places in board or possible moves\n",
    "            possible_moves = []\n",
    "            for i in range(LENGTH):\n",
    "                for j in range(LENGTH):\n",
    "                    if env.is_empty(i,j):\n",
    "                        possible_moves.append((i,j))\n",
    "            idx = np.random.choice(len(possible_moves))\n",
    "            next_move = possible_moves[idx]\n",
    "                \n",
    "        else:\n",
    "            pos_value = {}\n",
    "            best_value = -1\n",
    "            # take the best action based on current state values\n",
    "            for i in range(LENGTH):\n",
    "                for j in range(LENGTH):\n",
    "                    if env.is_empty(i,j):\n",
    "                        # what is the state if this move is made\n",
    "                        env.board[i,j] = self.sym\n",
    "                        state = env.get_state()\n",
    "                        # reset the env value just set above\n",
    "                        env.board[i,j] = 0\n",
    "                        pos_value[(i,j)] = self.V[state] \n",
    "                        if self.V[state] > best_value:\n",
    "                            best_value = self.V[state]\n",
    "                            next_move = (i,j)\n",
    "            \n",
    "            # if verbose is set then print the V values for all empty spaces\n",
    "            # this will only required when taking greedy action\n",
    "            if self.verbose:\n",
    "                print('Taking a greedy action')\n",
    "                for i in range(LENGTH):\n",
    "                    print('-------------------')\n",
    "                    for j in range(LENGTH):\n",
    "                        if env.is_empty(i,j):\n",
    "                            # print the V value\n",
    "                            print('| %.2f'%pos_value[(i,j)], end=\"\")\n",
    "                        elif env.board[i,j] == env.x:\n",
    "                            print(\"|  x  \", end=\"\")\n",
    "                        elif env.board[i,j] == env.o:\n",
    "                            print(\"|  o  \", end=\"\")\n",
    "                    print('|')\n",
    "                print('-------------------')\n",
    "        \n",
    "        # make the move\n",
    "        env.board[next_move[0], next_move[1]] = self.sym\n",
    "        \n",
    "        \n",
    "    def update(self, env):\n",
    "        # we want to backtrack over the states, so that:\n",
    "        # V(prev_state) = V(prev_state) + alpha*(V(next_state) - V(prev_state))\n",
    "        # now V(next_state) = reward if it is the last or most current state\n",
    "        # because this is the state which tells us whether we win/lose/draw\n",
    "        #\n",
    "        # NOTE: we do this update only after an end of episode(game)\n",
    "        \n",
    "        # set the V value for various states of this particular game\n",
    "        reward = env.reward(self.sym)\n",
    "        V_next = reward\n",
    "        for prev in reversed(self.state_history):\n",
    "            # we do not do this for last state because there is not next state for this\n",
    "            self.V[prev] = self.V[prev] + self.alpha*(V_next - self.V[prev])\n",
    "            V_next = self.V[prev]\n",
    "        \n",
    "        # clear the game history\n",
    "        self.reset_history()\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HUMAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def set_symbol(self, sym):\n",
    "        self.sym = sym\n",
    "        \n",
    "        \n",
    "    def update(self, env):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def update_state_history(self, s):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def take_action(self, env):\n",
    "        while True:\n",
    "            # break if we make a legal move\n",
    "            move = input('Enter coordinates i,j for your next move (i,j=0...2): ')\n",
    "            i, j = move.split(',')\n",
    "            i = int(i)\n",
    "            j = int(j)\n",
    "            if env.is_empty(i,j):\n",
    "                env.board[(i,j)] = self.sym\n",
    "                break        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_V_x(env, state_winner_triples):\n",
    "    # initialize state value as follows\n",
    "    # if x wins, V(s) = 1\n",
    "    # if x loses V(s) = -1\n",
    "    # if x draw V(s) = 0.5 \n",
    "    # otherwise, V(s) = 0\n",
    "    \n",
    "    V = np.zeros(env.num_states)\n",
    "    for state, winner, ended in state_winner_triples:\n",
    "        if ended:\n",
    "            if winner == env.x:\n",
    "                v=1\n",
    "            elif winner == env.o:\n",
    "                v=-1\n",
    "            else:\n",
    "                v=0.5\n",
    "        else:\n",
    "            v=0\n",
    "        # set V value for the state\n",
    "        V[state] = v\n",
    "    return V\n",
    "\n",
    "\n",
    "def initial_V_o(env, state_winner_triples):\n",
    "    # initialize state value as follows\n",
    "    # if o wins, V(s) = 1\n",
    "    # if o loses or draw, V(s) = 0\n",
    "    # otherwise, V(s) = 0.5\n",
    "    \n",
    "    V = np.zeros(env.num_states)\n",
    "    for state, winner, ended in state_winner_triples:\n",
    "        if ended:\n",
    "            if winner == env.o:\n",
    "                v=1\n",
    "            elif winner == env.x:\n",
    "                v=-1\n",
    "            else:\n",
    "                v=0.5\n",
    "        else:\n",
    "            v=0\n",
    "        # set V value for the state\n",
    "        V[state] = v\n",
    "    return V\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the states of the game and winner for the state if game is ended\n",
    "def get_state_hash_and_winner(env, i=0, j=0):\n",
    "    results = []\n",
    "    for v in [0, env.x, env.o]:\n",
    "        env.board[i,j] = v\n",
    "        if j==2:\n",
    "            # j goes back to 0 here\n",
    "            if i==2:\n",
    "                # the board is full, collect results and return\n",
    "                state = env.get_state()\n",
    "                ended = env.game_over()\n",
    "                winner = env.winner\n",
    "                results.append((state, winner, ended))            \n",
    "            else:\n",
    "                results += get_state_hash_and_winner(env, i+1, 0)\n",
    "        else:\n",
    "            # increment j. i stays the same\n",
    "            results += get_state_hash_and_winner(env, i, j+1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLAY GAME DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(p1, p2, env, verbose=False):\n",
    "    # set initialy current__player to None\n",
    "    current_player = None\n",
    "    \n",
    "    # loop until game is over\n",
    "    while not env.game_over():\n",
    "        # alternate player terms\n",
    "        # p1 always starts the game\n",
    "        if current_player == p1:\n",
    "            current_player = p2\n",
    "        else:\n",
    "            current_player = p1\n",
    "        # draw the board for the user who wants to make a move\n",
    "        if verbose:\n",
    "            env.draw_board() \n",
    "       \n",
    "        # current player makes a move\n",
    "        current_player.take_action(env)\n",
    "        \n",
    "        # update state histories\n",
    "        state = env.get_state()\n",
    "        p1.update_state_history(state)\n",
    "        p2.update_state_history(state)\n",
    "        \n",
    "    if verbose:\n",
    "        env.draw_board() \n",
    "\n",
    "    # do the value function update\n",
    "    p1.update(env)\n",
    "    p2.update(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████████████████████████████████▉                      | 10585/15000 [00:26<00:10, 419.26it/s]"
     ]
    }
   ],
   "source": [
    "# initialize player 1 and player 2\n",
    "p1 = Agent(eps=0.1, alpha=0.5, verbose=False)\n",
    "p2 = Agent(eps=1, alpha=0.5, verbose=False)\n",
    "\n",
    "# create tic tac toe environment\n",
    "env = Environment()\n",
    "\n",
    "# give each player their symbol\n",
    "p1.set_symbol(env.x)\n",
    "p2.set_symbol(env.o)\n",
    "\n",
    "# get the initital V values\n",
    "state_winner_triples = get_state_hash_and_winner(env)\n",
    "Vx = initial_V_x(env, state_winner_triples)\n",
    "Vo = initial_V_o(env, state_winner_triples)\n",
    "\n",
    "# set the initial V values for player 1 and player 2 if both are AI\n",
    "p1.set_V(Vx)\n",
    "p2.set_V(Vo)\n",
    "\n",
    "# train p1 as player 1\n",
    "for i in tqdm(range(15000)):\n",
    "    p2.eps = p2.eps/(i/2000+1)\n",
    "    play_game(p1, p2, Environment(), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HUMAN VS AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0...2): 1,1\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "|   | x |   |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "Taking a greedy action\n",
      "-------------------\n",
      "| -0.15| -0.11| -0.11|\n",
      "-------------------\n",
      "| -0.16|  x  | 0.00|\n",
      "-------------------\n",
      "| -0.13| -0.10| -0.17|\n",
      "-------------------\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "|   | x | o |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0...2): 0,0\n",
      "-------------\n",
      "| x |   |   |\n",
      "-------------\n",
      "|   | x | o |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "Taking a greedy action\n",
      "-------------------\n",
      "|  x  | -0.13| 0.13|\n",
      "-------------------\n",
      "| -0.12|  x  |  o  |\n",
      "-------------------\n",
      "| -0.12| -0.16| -0.16|\n",
      "-------------------\n",
      "-------------\n",
      "| x |   | o |\n",
      "-------------\n",
      "|   | x | o |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0...2): \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mident\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\jupyter_client\\session.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[0;32m    802\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m             \u001b[0mmsg_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[1;34m(self, flags, copy, track)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;31m# have first part already, only loop while more to receive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-252-981f4f735e7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mplay_game\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhuman\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'play again ? Y/N'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Y'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-f1d4dc283e3c>\u001b[0m in \u001b[0;36mplay_game\u001b[1;34m(p1, p2, env, verbose)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# current player makes a move\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mcurrent_player\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# update state histories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-71395b9f4928>\u001b[0m in \u001b[0;36mtake_action\u001b[1;34m(self, env)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;31m# break if we make a legal move\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Enter coordinates i,j for your next move (i,j=0...2): '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         )\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize player 1 and player 2\n",
    "human = Human()\n",
    "\n",
    "# give each player their symbol\n",
    "human.set_symbol(env.x)\n",
    "p1.verbose=True\n",
    "p2.verbose=True\n",
    "p2.eps=0\n",
    "while True:\n",
    "    play_game(human, p2, Environment(), True)\n",
    "    if input('play again ? Y/N')=='Y':\n",
    "        continue\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19683"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
